# NCP/Niabrain Routes vs Our Current Architecture

**Date:** October 24, 2025  
**Question:** How/why is the NCP/niabrain using routes? Is there a corrollary in our current work?

---

## TL;DR

**NCP uses FastAPI routes because it's a REST API service** that sits between the frontend and backend services. **Niabrain uses routes because it's also a FastAPI app** that handles WebSocket connections for voice pipelines.

**Our pipecat-daily-bot already uses FastAPI routes in `server.py`** - we just don't have the tool routes pattern yet.

---

## Architecture Comparison

### NCP (Nia Context Protocol) - REST API Gateway

```
Frontend (interface)
    ‚Üì HTTP POST
NCP Server (FastAPI)
    ‚îú‚îÄ‚îÄ /showAgenda (route)
    ‚îú‚îÄ‚îÄ /showSpeakers (route)
    ‚îú‚îÄ‚îÄ /searchYouTubeVideos (route)
    ‚îî‚îÄ‚îÄ ...
    ‚Üì calls services
Services Layer
    ‚îú‚îÄ‚îÄ agenda_service.py
    ‚îú‚îÄ‚îÄ speaker_service.py
    ‚îî‚îÄ‚îÄ youtube_service.py
    ‚Üì HTTP GET/POST
External APIs (Mesh, YouTube, etc.)
```

**Why routes?** NCP is a **REST API server** - it exposes HTTP endpoints for each tool function.

---

### Niabrain - WebSocket Voice Server

```
Frontend (interface)
    ‚Üì WebSocket handshake
Niabrain Server (FastAPI)
    ‚îú‚îÄ‚îÄ POST /api/ws/connect (route - get WS URL)
    ‚îî‚îÄ‚îÄ WebSocket /ws (route - voice pipeline)
    ‚Üì builds pipeline
Pipecat Pipeline (voice-to-voice)
    ‚îú‚îÄ‚îÄ STT (Deepgram)
    ‚îú‚îÄ‚îÄ LLM (OpenAI)
    ‚îú‚îÄ‚îÄ TTS (ElevenLabs)
    ‚îî‚îÄ‚îÄ Tools (via HTTP to NCP)
```

**Why routes?** Niabrain is a **WebSocket server** - it needs HTTP endpoints for connection setup and WebSocket endpoint for voice streaming.

---

### Our Pipecat-Daily-Bot - Hybrid Architecture

```
Frontend (interface)
    ‚Üì HTTP POST
server.py (FastAPI) ‚Üê WE ALREADY HAVE ROUTES!
    ‚îú‚îÄ‚îÄ POST /join (spawn bot process)
    ‚îú‚îÄ‚îÄ POST /leave (terminate bot)
    ‚îú‚îÄ‚îÄ GET /health (health check)
    ‚îú‚îÄ‚îÄ WebSocket /admin (admin messages)
    ‚îî‚îÄ‚îÄ GET /events (SSE stream)
    ‚Üì spawns process
bot.py (Pipecat pipeline)
    ‚îú‚îÄ‚îÄ Daily.co transport (WebRTC)
    ‚îú‚îÄ‚îÄ STT ‚Üí LLM ‚Üí TTS
    ‚îî‚îÄ‚îÄ Tools (direct to Mesh GraphQL)
```

**Why routes?** `server.py` is a **control plane** - it manages bot lifecycle via HTTP endpoints.

---

## Key Difference: Where Tools Are Invoked

### NCP Pattern (Tool Routes)

```python
# NCP exposes tools as HTTP routes
@router.post("/searchYouTubeVideos")  # ‚Üê Tool is a route
@tool_route(name="searchYouTubeVideos", ...)
async def search_youtube_videos(request: YouTubeSearchRequest):
    # Call service layer
    result = await youtube_service.search_videos(request.query)
    return {"system_message": "...", "metadata": result}
```

**Who calls it:** LLM (via HTTP POST to NCP server)

**Data flow:**
```
LLM function call ‚Üí HTTP POST /searchYouTubeVideos ‚Üí NCP route ‚Üí Service ‚Üí External API
```

---

### Niabrain Pattern (Tool Functions via HTTP)

```python
# Niabrain calls NCP tools via HTTP
async def call_ncp_tool(assistant_name, function_name, params):
    endpoint = f"/{function_name}"  # e.g., /searchYouTubeVideos
    payload = {"assistantName": assistant_name, **params.arguments}
    
    # HTTP POST to NCP server
    result = await _make_ncp_request(endpoint, payload)
    await params.result_callback(result)
```

**Who calls it:** Pipecat LLM service (function calling handler)

**Data flow:**
```
LLM function call ‚Üí Niabrain handler ‚Üí HTTP POST to NCP ‚Üí NCP route ‚Üí Service
```

---

### Our Current Pattern (Direct Mesh Integration)

```python
# We call Mesh GraphQL directly from tool handlers
async def create_note_handler(function_name, tool_call_id, args, ...):
    # Direct GraphQL call
    note = await create_note(mesh_client, args["title"], args["content"], ...)
    
    # Emit event to frontend
    await forwarder.emit_tool_event(events.NOTE_CREATED, {"note_id": note.id})
    
    # Return to LLM
    await result_callback(FunctionCallResultFrame(...))
```

**Who calls it:** Pipecat LLM service (function calling handler)

**Data flow:**
```
LLM function call ‚Üí Tool handler ‚Üí Actions ‚Üí Mesh GraphQL ‚Üí Database
```

---

## The Routes Question: Do We Need Them?

### What NCP Routes Provide

1. **HTTP interface for tools** - Expose tools via REST API
2. **Separation of concerns** - Tools live in separate service
3. **Language agnostic** - Any language can call HTTP endpoints
4. **Centralized tool server** - One NCP serves multiple clients
5. **Easy testing** - Can test tools via curl/Postman

### What We Already Have

Our `server.py` **already has routes**:

```python
# apps/pipecat-daily-bot/bot/server.py (FastAPI app)

@app.post("/join")
async def join_room(request: JoinRequest = ...) -> JoinResponse:
    """Spawn a bot process for a room."""
    ...

@app.post("/leave")
async def leave_room(request: LeaveRequest = ...) -> Response:
    """Terminate a bot session."""
    ...

@app.get("/health")
async def health() -> HealthResponse:
    """Health check endpoint."""
    ...

@app.websocket("/admin")
async def admin_websocket(websocket: WebSocket):
    """Admin control WebSocket."""
    ...

@app.get("/events")
async def events_stream(room_url: str = ...) -> StreamingResponse:
    """SSE stream for bot events."""
    ...
```

**We have routes for:**
- Bot lifecycle management (join/leave)
- Health monitoring
- Admin control
- Event streaming

**We DON'T have routes for:**
- Individual tool functions (like `/createNote`, `/searchYouTube`)

---

## Should We Add Tool Routes?

### Option A: Current Pattern (Direct Integration)

```python
# bot/tools/notes_tools.py
@bot_tool(name="bot_create_note", ...)
async def create_note_handler(...):
    # Direct call to Mesh
    note = await create_note(mesh_client, ...)
    await result_callback(...)
```

**Pros:**
- ‚úÖ Direct, fast (no HTTP overhead)
- ‚úÖ Type-safe (Pydantic ‚Üí GraphQL)
- ‚úÖ Simpler architecture (fewer moving parts)
- ‚úÖ Tools are part of bot process

**Cons:**
- ‚ùå Tools can't be shared across services
- ‚ùå Testing requires bot environment
- ‚ùå Tightly coupled to Mesh

---

### Option B: NCP-Style Tool Routes

```python
# server.py - Add tool routes
@app.post("/tools/createNote")
@bot_tool_route(name="bot_create_note", ...)
async def create_note_route(request: CreateNoteRequest):
    # Call action layer
    note = await create_note(mesh_client, ...)
    return {"system_message": "...", "metadata": {...}}

# bot.py - Call via HTTP
async def create_note_handler(...):
    # HTTP POST to server.py
    result = await call_bot_tool_api("/tools/createNote", args)
    await result_callback(result)
```

**Pros:**
- ‚úÖ Tools exposed via HTTP (testable with curl)
- ‚úÖ Could be shared with other services
- ‚úÖ Separation: control plane vs tools
- ‚úÖ Matches NCP pattern (easier migration)

**Cons:**
- ‚ùå HTTP overhead for every tool call
- ‚ùå More complex architecture
- ‚ùå Requires HTTP client in bot.py
- ‚ùå Tools run in server.py process (different from bot)

---

### Option C: Hybrid (Recommended)

```python
# server.py - Expose tool registry via route (read-only)
@app.get("/tools")
async def get_tools() -> ToolRegistryResponse:
    """Get available tools for dynamic discovery."""
    discovery = BotToolDiscovery()
    tools = discovery.discover_tools()
    return {"tools": tools, "total": len(tools)}

# bot.py - Tools execute directly (as now)
@bot_tool(name="bot_create_note", ...)
async def create_note_handler(...):
    # Direct execution (no HTTP)
    note = await create_note(mesh_client, ...)
    await result_callback(...)
```

**Pros:**
- ‚úÖ Best of both worlds
- ‚úÖ Direct execution (fast)
- ‚úÖ Discoverable via HTTP (frontend can query)
- ‚úÖ Simple architecture
- ‚úÖ Testable (unit tests for handlers)

**Cons:**
- ‚ö†Ô∏è Tools not callable via HTTP (but do we need that?)

---

## Corrollary in Our Work

### Direct Answer: Yes, We Have a Corrollary

**NCP's `/tools` endpoint with `@tool_route`** ‚Üî **Our `/tools` endpoint with `@bot_tool`**

**Difference:** 
- **NCP:** Tool routes are **executable** HTTP endpoints
- **Us:** Tool endpoint is **informational** (returns metadata)

### Implementation (Already Planned!)

From **Ticket #6** in `MIGRATION_TICKETS.md`:

```python
# This is what we planned to add
@router.get("/api/bot/tools")
async def get_bot_tools(category: Optional[str] = Query(None)):
    """Get available bot tools for dynamic frontend loading."""
    discovery = BotToolDiscovery()
    
    if category:
        tools = discovery.get_tools_by_category(category)
    else:
        tools = discovery.discover_tools()
    
    return {
        "tools": [
            {
                "name": meta["name"],
                "description": meta["description"],
                "category": meta["category"],
                "parameters": meta["parameters"],
                "passthrough": meta["passthrough"]
            }
            for name, meta in tools.items()
        ],
        "total": len(tool_list)
    }
```

**This is the corrollary** - we expose tool **metadata** via HTTP, but **execution** happens in-process.

---

## Why Different Architectures?

### NCP: Multi-Tenant Tool Server

**Use case:** Serve multiple clients (different bots, different apps)

```
Niabrain Bot 1 ‚îÄ‚îÄ‚îê
Niabrain Bot 2 ‚îÄ‚îÄ‚îº‚îÄ‚îÄ> NCP (shared tool server)
Interface App   ‚îÄ‚îÄ‚î§
Dashboard       ‚îÄ‚îÄ‚îò
```

**Reason for routes:** Tools must be accessible via network

---

### Our Bot: Integrated Pipeline

**Use case:** Single bot process per room

```
Room A ‚Üí Bot Process A (tools embedded)
Room B ‚Üí Bot Process B (tools embedded)
Room C ‚Üí Bot Process C (tools embedded)
```

**Reason for direct calls:** Tools are part of the bot, no need for HTTP

---

## When Would We Need Tool Routes?

### Scenario 1: Separate Tool Service

If we wanted to extract tools into a separate service:

```
Bot Process 1 ‚îÄ‚îÄ‚îê
Bot Process 2 ‚îÄ‚îÄ‚îº‚îÄ‚îÄ> Tool Service (HTTP routes)
Dashboard      ‚îÄ‚îÄ‚îò
```

**Benefits:**
- Share tools across multiple bot instances
- Independent scaling (tools vs pipelines)
- Easier testing (test tools independently)

**Tradeoffs:**
- Network latency
- More complex deployment
- Need HTTP client in bot

---

### Scenario 2: Tool Marketplace

If we wanted third-parties to add tools:

```
Core Tools (built-in)
    +
Plugin Tools (HTTP endpoints)
    +
Custom Tools (user-defined)
    ‚Üì
Bot discovers and registers all
```

**Benefits:**
- Extensibility
- Community plugins
- No bot restarts for new tools

**Tradeoffs:**
- Security concerns
- Version management
- Error handling across network

---

## Recommendation

### For Now: Stick with Current Pattern + Discovery API

**Keep:**
- Direct tool execution (fast, simple)
- Tools in bot process (integrated)
- Actions layer (business logic)

**Add:**
- `GET /api/bot/tools` endpoint (Ticket #6)
- `@bot_tool` decorators (Ticket #1)
- `BotToolDiscovery` (Ticket #2)

**Benefits:**
- ‚úÖ Fast execution
- ‚úÖ Simple architecture
- ‚úÖ Frontend can discover tools dynamically
- ‚úÖ No breaking changes

---

### Future: Consider Tool Routes If...

**Scenario 1:** You need to share tools across multiple services
- ‚Üí Add tool routes to `server.py`
- ‚Üí Bot calls tools via HTTP

**Scenario 2:** You want to separate tool scaling from pipeline scaling
- ‚Üí Extract tools to separate service
- ‚Üí Multiple bots share one tool service

**Scenario 3:** You want third-party tool plugins
- ‚Üí Plugin system with HTTP-based tools
- ‚Üí Discovery includes external endpoints

---

## Code Example: What It Would Look Like

### If We Added Tool Routes (Like NCP)

```python
# server.py - Add tool routes
from fastapi import APIRouter
from bot.decorators import bot_tool_route

tool_router = APIRouter()

@tool_router.post("/tools/createNote")
@bot_tool_route(name="bot_create_note", ...)
async def create_note_endpoint(request: CreateNoteRequest):
    """HTTP endpoint for creating notes."""
    from bot.actions.notes_actions import create_note
    from bot.mesh_client import MeshClient
    
    mesh_client = MeshClient(...)
    note = await create_note(
        mesh_client,
        request.title,
        request.content,
        request.tenant_id,
        request.user_id
    )
    
    return {
        "system_message": f"Created note: {note.title}",
        "metadata": {"note_id": note.id}
    }

# Include in main app
app.include_router(tool_router, tags=["Tools"])

# bot.py - Call via HTTP
async def create_note_handler(...):
    """LLM function calling handler."""
    # HTTP POST instead of direct call
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8080/tools/createNote",
            json={
                "title": args["title"],
                "content": args["content"],
                "tenant_id": get_tenant_id(),
                "user_id": get_user_id()
            }
        )
        result = response.json()
    
    await result_callback(FunctionCallResultFrame(...))
```

**Change needed:**
- Add ~30 tool route endpoints to `server.py`
- Change bot handlers to HTTP clients
- Add request/response models
- Handle HTTP errors

**Benefit:**
- Tools accessible via HTTP (curl testable)
- Could be shared across services

**Cost:**
- ~200ms latency per tool call (HTTP overhead)
- More complex architecture
- HTTP error handling

---

## Summary

### The Answer

**Q:** How/why is NCP/niabrain using routes?

**A:** 
- **NCP uses routes** because it's a REST API service exposing tools via HTTP
- **Niabrain uses routes** because it's a WebSocket server for voice pipelines
- **We already use routes** in `server.py` for bot control (join/leave/health)

**Q:** Is there a corrollary in our current work?

**A:** 
- **Yes:** `GET /api/bot/tools` endpoint (planned in Ticket #6)
- **Difference:** Ours returns metadata, NCP's are executable
- **Reason:** Our tools execute in-process (faster), NCP's via HTTP (shareable)

---

### Decision Matrix

| Aspect | Direct (Current) | Tool Routes (NCP-style) |
|--------|------------------|-------------------------|
| **Execution Speed** | ‚ö° Fast (in-process) | üê¢ Slower (HTTP) |
| **Architecture** | ‚úÖ Simple | ‚ùå Complex |
| **Testability** | ‚ö†Ô∏è Unit tests | ‚úÖ curl/Postman |
| **Shareability** | ‚ùå Bot-only | ‚úÖ Cross-service |
| **Discovery** | ‚úÖ Via /tools API | ‚úÖ Via routes |
| **Deployment** | ‚úÖ Single process | ‚ùå Multiple services |

**Recommendation:** Stick with direct execution, add discovery API (Ticket #6)

---

### When to Reconsider

Add tool routes if you need:
1. **Multi-service tool sharing** (multiple bots, dashboard, etc.)
2. **Independent tool scaling** (scale tools separately)
3. **Third-party plugins** (external tool providers)
4. **Tool marketplace** (community-contributed tools)

Until then, direct execution is faster and simpler. ‚úÖ
