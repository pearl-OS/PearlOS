# Patent Discovery Report: Nia Universal Platform

**Date:** December 29, 2025  
**Status:** Initial Discovery & Analysis  
**Last Updated:** December 29, 2025 (Prior Art Research Complete)

---

## Executive Summary

After deep analysis of the apps and packages in the Nia Universal codebase, we've identified several innovation clusters with patent potential. These range from novel architectures to specific technical implementations that appear unique in the AI assistant/voice bot space.

**Research conducted on December 29, 2025** has revealed varying levels of viability based on existing prior art and competitive landscape. After thorough prior art research, **3 innovations** are recommended for immediate patent filing, while others have been moved to "Not Worth Pursuing" due to significant prior art overlap.

---

## üèÜ HIGH PATENT POTENTIAL (File Immediately)

### 1. Intelligent AI Context Restoration for Applet Modification

**Location:** `apps/interface/src/features/HtmlGeneration/lib/context-management.ts`

**Viability Assessment: ‚úÖ VERY HIGH - GREENFIELD OPPORTUNITY**

#### Prior Art Research (December 2025)

**Related Research & Products:**
- **Sakana AI NAMM** (Neural Attention Memory Models) - Token-level "remember or forget" decisions, reduces cache memory by 75%. Published research, not patent.
- **Maxim AI** - Context window management strategies including selective context injection, compression techniques
- **Kinde** - Engineering guides for token limits in large codebases
- **GoCodeo** - Context window optimization through prompt engineering

**Key Finding: This is an ACTIVE research area with NO dominant patents found.**

**What Exists:**
- General prompt engineering best practices
- Token counting and truncation strategies
- Research papers on attention memory models
- LLM provider documentation on context limits

**What Does NOT Exist (as patents):**
- **Provider-specific adaptive method selection** - No patents found on dynamically choosing context strategy based on AI model capabilities
- **Three-tier fallback system** (direct ‚Üí appendix ‚Üí summary) - Novel architecture
- **Output token reservation calculation** - Subtracting expected output from context budget
- **Appendix-based code injection** - Separate context block for code while keeping summary in main prompt

This appears to be a **greenfield opportunity**. Context window management is discussed extensively in blog posts and documentation, but no patents were found covering:

1. **Adaptive method selection** based on provider + model + content size
2. **Three-tier fallback architecture** with specific thresholds
3. **Output reservation calculation** ensuring space for response
4. **Appendix pattern** for large codebase modification

**Competitive Landscape:**
- Most tools use simple truncation or RAG (retrieval)
- No evidence of tiered fallback systems
- Provider-specific optimization appears novel

**Innovation:**
- Three-tier context method selection (direct, appendix, summary) based on content size and AI model capabilities
- Provider-specific token budget optimization with output reservation
- Smart code compression for large applets while preserving modification capability
- Modification history tracking for incremental AI updates

**Context Method Selection:**
| Method | Use Case | Size Threshold |
|--------|----------|----------------|
| Direct | Small applets | < 15,000 chars, < 70% available tokens |
| Appendix | Medium applets | < 50,000 chars, < 90% available tokens |
| Summary | Large applets | > 50,000 chars or token budget exceeded |

**Novel Claims:**
1. **Adaptive context restoration method selection** based on AI provider, model variant, and content size, with automatic fallback between tiers
2. **Provider-specific token budget allocation** with explicit output space reservation, dynamically calculated per model
3. **Appendix-based context injection pattern** for large codebases, separating structural summary from full code context

**Provider Token Limits (Built-in):**
```typescript
// Example: Claude Sonnet 4 = 200k context, 12k output reserved
// Available for input: 200k - 12k - 1k buffer = 187k tokens
```

---

### 2. Voice Confusion Prevention System for Avatar Lipsync

**Location:** `apps/interface/src/features/RiveAvatarLipsync/`

#### Prior Art Research (December 2025)

**Related Patents Found:**
- **US20170039750A1** - "Avatar facial expression and/or speech driven animations" (Intel) - Covers facial expression tracking + speech tracking for avatar animation, but does NOT address voice confusion prevention
- **US20120130717A1** - "Real-time Animation for an Expressive Avatar" - Speech-driven emotional state animation
- **Huawei MetaStudio Patents** - Lip-sync accuracy, multi-language support, AI-driven eye correction

**Competitive Landscape:**
- **Tavus Sparrow Model** - Advanced turn-taking with confidence scoring (0.52 threshold), semantic/lexical analysis for conversation endpoints. Uses 100ms pause detection. **This is the closest competitor.**
- **Deepgram** - Voice AI patents for speech processing, but focused on transcription accuracy, not avatar control
- **D-ID, Synthesia, HeyGen** - Focus on video generation quality, not real-time voice confusion prevention

**Acoustic Echo Cancellation (AEC) Patents:**
- **US12003673B2** - Acoustic echo cancellation for smart speakers
- **US7272224B1** - Traditional echo cancellation (microphone ‚Üí speaker isolation)
- These address **audio-level** echo, NOT **semantic-level** voice confusion in avatar systems

**Viability Assessment: ‚úÖ HIGH**

**Key Differentiators Not Found in Prior Art:**
1. **Multi-factor confidence scoring with specific weights** (40% content, 30% finality, 20% substance, 10% recency) - Tavus uses binary confidence (above/below 0.52), we use weighted multi-factor
2. **Signal reliability hierarchy** - Explicit ranking of signal sources (transcript > conversation-update > model-output > speech-start > volume) - Novel approach
3. **RULE 6 enforcement** - Absolute user speech priority with immediate animation freeze at transcript level - Different from Tavus which waits for turn-taking endpoint
4. **50ms ultra-fast cutoff** - Faster than Tavus's 100ms pause detection threshold

**Existing patents focus on:**
- Acoustic echo cancellation (audio signal processing)
- Speech-driven avatar animation (lipsync accuracy)
- Turn-taking timing (when to respond)

**Our innovation focuses on:**
- Preventing the avatar from "hearing itself" at the semantic/transcript level
- User priority enforcement with immediate visual response
- Multi-signal confidence scoring for animation permission

**Innovation:**
- Multi-factor confidence scoring for speech attribution (40% content, 30% finality, 20% substance, 10% recency)
- Signal reliability hierarchy that prevents feedback loops from the AI's own voice being detected as user input
- "RULE 6" enforcement - absolute user speech priority with immediate animation freeze
- 50ms ultra-fast user speech detection with transcript-only triggering

**Signal Reliability Hierarchy:**
1. Most Reliable: transcript messages with `role: 'assistant'`
2. Very Reliable: conversation-update with `transcriptType: 'final'`
3. Reliable: model-output messages
4. Moderately Reliable: assistant-speech-start/end
5. Less Reliable: Volume-based detection
6. Avoid: speech-update events (prone to feedback loops)

**Novel Claims (Strengthened):**
1. A method for preventing voice confusion in real-time avatar animation systems using **weighted multi-factor confidence scoring** with explicit factor weights
2. **Signal reliability hierarchy** for distinguishing user vs. assistant speech in voice interfaces, operating at the transcript semantic level rather than audio level
3. Ultra-fast animation cutoff system (**50ms or less**) prioritizing user speech detection over assistant animations with **immediate visual response**

**Key Implementation:**
```typescript
// Multi-factor confidence calculation
const calculateConfidence = (transcriptText, transcriptType, currentTime) => {
  let confidence = 0;
  if (transcriptText.length > 0) confidence += 0.4;      // Has content
  if (transcriptType === 'final') confidence += 0.3;     // Final transcript
  if (transcriptText.length > 10) confidence += 0.2;     // Substantial
  if (currentTime - lastSpeech < 5000) confidence += 0.1; // Recent activity
  return Math.min(confidence, 1.0);
};
```

---

### 3. Flow-Managed Conversation Pacing with Beat Scheduling

**Location:** `apps/pipecat-daily-bot/bot/flows/pacing.py`, `apps/pipecat-daily-bot/bot/flows/nodes.py`

#### Prior Art Research (December 2025)

**Related Patents Found:**
- **US12340181B1** - "Conversation dialogue orchestration in virtual assistant communication sessions" (Fidelity, 2025) - **CLOSEST PRIOR ART**. Covers dialogue orchestration but focuses on financial services virtual assistants, multi-turn conversation management
- **Openstream.ai Patent** - Multimodal conversational AI with simultaneous multiple inputs
- **US11431660B1** - "System and method for collaborative conversational AI" - Multi-agent collaborative conversation

**Competitive Landscape:**
- **Tavus Sparrow** - Turn-taking with confidence scoring, but focused on **when to respond**, NOT scheduled conversational prompts
- **Amazon Alexa Skills / Google Actions** - Conversation flow management, but driven by user intents, not time-based beats
- **Revenue.io** - Adaptive real-time conversational systems for call monitoring

**What US12340181B1 Covers:**
- Dialogue orchestration server establishing communication sessions
- Multi-turn conversation management
- Virtual assistant response coordination

**What US12340181B1 Does NOT Cover:**
- Time-based "beat" scheduling with personality-driven prompts
- Scheduled wrap-up awareness with configurable timing
- Non-intrusive summary observation via decorator injection

**Viability Assessment: ‚úÖ HIGH**

**Key Differentiators:**
1. **Time-based "beats"** - Scheduled conversational prompts at specific intervals (e.g., 60s, 120s, 180s into call) - NOT found in prior art
2. **Personality-driven timing** - Beats derived from personality record, not static rules
3. **Repeat intervals with next-beat limiting** - Beats repeat until the next beat's start time
4. **`RESET_WITH_SUMMARY` context strategy** - Context window management integrated with pacing
5. **Summary tap decorator injection** - Non-intrusive observation pattern for AI summaries

**Prior art focuses on:**
- Reactive dialogue (respond to user intents)
- Turn-taking timing (when to speak after user)
- Multi-turn context management

**Our innovation focuses on:**
- Proactive time-scheduled conversation guidance
- Personality-configurable beat messages
- Wrap-up scheduling with graceful conversation ending

**Innovation:**
- Conversation "beats" system - scheduled conversational prompts at specific time intervals
- Personality-driven conversation pacing with wrap-up scheduling
- Context-preserving node transitions (`RESET_WITH_SUMMARY` strategy)
- Summary tap for non-intrusive conversation flow observation

**Novel Claims (Strengthened):**
1. A system for scheduling conversational "beats" - **time-triggered prompts that proactively guide conversation flow** independent of user input, with configurable repeat intervals
2. **Personality-driven** conversation pacing controller with **configurable wrap-up scheduling** derived from personality records
3. Non-intrusive observation pattern for AI conversation summaries using **decorator injection on flow manager methods**

**Beat Plan Structure:**
```python
@dataclass
class BeatPlan:
    message: str           # The conversational prompt
    start_time: float      # When to trigger (seconds from call start)
    next_start_time: float # When the next beat starts (for repeat limiting)
```

**Key Features:**
- Beats repeat at configurable intervals until the next beat's start time
- Wrap-up scheduling with personality-specific prompts
- Event emission for external systems to react to pacing events

---

## Viability Summary Matrix

| # | Innovation | Viability | Prior Art Risk | Recommendation |
|---|-----------|-----------|----------------|----------------|
| 1 | Context Restoration | ‚úÖ VERY HIGH | VERY LOW (no patents found) | **FILE PATENT IMMEDIATELY** - Greenfield |
| 2 | Voice Confusion Prevention | ‚úÖ HIGH | LOW (AEC patents are audio-level) | **FILE PATENT** - Strong differentiators |
| 3 | Conversation Beats | ‚úÖ HIGH | MODERATE (US12340181B1 is different domain) | **FILE PATENT** - Time-based proactive |
| 4 | Applet Versioning | ‚ö†Ô∏è MODERATE | MODERATE (semantic versioning exists) | Potential niche claims |

---

## ü•à MODERATE PATENT POTENTIAL

### 4. Applet Versioning with Change-Type Detection

**Location:** `apps/interface/src/features/HtmlGeneration/lib/versioning-system.ts`

**Innovation:**
- Automatic change-type detection (minor vs. major) from modification requests
- Similar app detection with base name and version parsing
- User-choice preservation for versioning preferences
- Semantic versioning for user-generated content (v1 ‚Üí v1.1 for minor, v1 ‚Üí v2 for major)

**Novel Claims:**
1. Automated version increment recommendation based on modification intent analysis
2. Similar content detection for user-generated applets with version family grouping

**Version Strategy:**
```typescript
// Minor change detected ‚Üí suggest v1.1 (update original)
// Major change detected ‚Üí suggest v2 (create new version)
// Always presents both options to user with recommendation
```

---

## üîç SUPPORTING INNOVATIONS (Utility Patent Potential)

### 5. Event Bus with Schema Versioning

**Location:** `apps/pipecat-daily-bot/bot/eventbus/bus.py`

- Envelope-wrapped events with schema version for backward compatibility
- Wildcard subscription pattern with streaming fan-out to SSE/WebSocket consumers
- Unified event taxonomy across Python bot and TypeScript frontend (`packages/events/`)

### 6. Warm Pool Bot Dispatch

**Location:** `apps/pipecat-daily-bot/bot/bot_operator.py`, `apps/pipecat-daily-bot/bot/runner_main.py`

- Pre-warmed bot instances in Redis standby pool (`bot:standby:pool`)
- Instant dispatch to ready bots vs. cold-start fallback
- Automatic pool replenishment after dispatch

### 7. Smart Participant Name Resolution

**Location:** `apps/pipecat-daily-bot/bot/flows/sanitization.py`

- Multi-source name derivation with priority chain:
  1. `info.userName` (user-entered display name)
  2. `sessionUserName` (from session metadata)
  3. `sessionUserEmail` (email as fallback)
  4. Profile `first_name` (from UserProfile record)
- Profile field whitelisting for privacy protection

### 8. TTS Session Pool Warming

**Location:** `apps/chorus-tts/chorus_tts/kokoro_engine.py`

- Pre-compiled TTS sessions with GPU kernel warming
- Session pooling for reduced first-request latency
- Configurable pool size with automatic session recycling

---

## üìã Recommended Next Steps (Updated Based on Research)

### Priority 1: FILE PATENTS IMMEDIATELY üö®
Based on prior art research, these have the highest viability:

1. **Context Restoration System (Innovation #1)** - **GREENFIELD OPPORTUNITY**
   - No competing patents found
   - Three-tier architecture is novel
   - Provider-specific optimization is defensible
   - Start with provisional patent

2. **Voice Confusion Prevention (Innovation #2)** - **STRONG DIFFERENTIATION**
   - Existing patents are audio-level (AEC)
   - Our semantic-level approach is novel
   - Multi-factor confidence scoring is unique
   - 50ms threshold is faster than competitors

3. **Conversation Beats (Innovation #3)** - **NOVEL DOMAIN APPLICATION**
   - US12340181B1 covers different domain (financial VA)
   - Time-based proactive prompts not patented
   - Personality-driven pacing is novel

### Priority 2: Conditional Filing
4. **Applet Versioning (Innovation #4)** - **NICHE POTENTIAL**
   - Change-type detection from modification intent is novel
   - Semantic versioning itself is prior art, but AI-driven version recommendation may have claims

### Competitive Intelligence Gathered

| Competitor | Focus Area | Gap vs. Our Innovation |
|------------|-----------|----------------------|
| **Tavus Sparrow** | Turn-taking timing | We do voice confusion prevention, they do turn detection |
| **Hasura/PostGraphile** | Single-source GraphQL | We do multi-source federation with tenant isolation |
| **Sakana AI NAMM** | Token memory optimization | We do tiered context strategy selection |
| **Fidelity US12340181B1** | Dialogue orchestration | We do time-scheduled proactive beats |

### Documentation Requirements
For each patent filing, prepare:
- [ ] Detailed flowcharts showing decision trees
- [ ] Performance benchmarks (50ms response, etc.)
- [ ] Code snippets demonstrating implementation
- [ ] Comparison tables vs. prior art

---

## ‚ùå NOT WORTH PURSUING (Prior Art Blocks)

The following innovations were evaluated but **should not be pursued** for patent filing due to significant prior art overlap or being implementations of documented standards.

### A. Prism Refractory (GraphQL Schema Introspection)

**Location:** `packages/prism/src/refractory/index.ts`

**Why Not Patentable:**
- **Hasura** (2017): Automatic GraphQL API generation from PostgreSQL with real-time subscriptions
- **PostGraphile** (2016): PostgreSQL ‚Üí GraphQL introspection with smart relation detection
- **Prisma** (2019): Schema-first ORM with automatic GraphQL generation

**Prior Art Assessment: ‚ùå HIGH OVERLAP**
Our implementation uses the same core technique: database introspection ‚Üí automatic GraphQL schema generation. While we add tenant isolation, this is a configuration concern, not a novel technical approach.

**Potential Pivot (Not Recommended):** Multi-source federation unifying PostgreSQL + external APIs (Google, S3) could have niche claims, but would require significant implementation work with uncertain outcome.

---

### B. Incremental OAuth Scope Acquisition

**Location:** `packages/prism/src/core/oauth/incremental-auth.service.ts`

**Why Not Patentable:**
- **Google OAuth Documentation** explicitly describes the `include_granted_scopes: true` pattern for incremental authorization
- This is an **implementation of a vendor-specified protocol**, not an invention
- The technique is documented in Google's official OAuth 2.0 guides since 2018

**Prior Art Assessment: ‚ùå FOLLOWING VENDOR PROTOCOL**
We're implementing Google's recommended pattern exactly as documented. No novel claims possible.

---

### C. Multi-User Voice Chat Facilitation

**Location:** `apps/pipecat-daily-bot/bot/flows/participantsAggregator.ts`, `MultiUserContextAggregator` class

**Why Not Patentable:**
- **US20250080481A1 "HyperChat"** (Published Jan 2025) - Extensively covers AI-facilitated multi-user conversations:
  - Multi-participant conversation aggregation with speaker identification
  - AI moderator for group voice interactions
  - Turn-taking management in multi-user sessions
  - "HyperChat sessions involving video/audio communication" with AI facilitation
  
**Prior Art Assessment: ‚ùå BLOCKED BY HYPERCHAT PATENT**

Our implementation prefixes transcriptions with `[User {name}, pid: {id}]: {text}` for multi-speaker context aggregation‚Äîthis is directly covered by HyperChat's claims on "aggregating multi-participant context for AI processing."

**Additional Prior Art:**
- **Otter.ai** (2016): Multi-speaker transcription with speaker diarization
- **Fireflies.ai** (2017): Meeting assistant with participant identification
- **Zoom AI Companion** (2023): Multi-user meeting summarization
- **Tavus Sparrow** (2024): Multi-participant video AI with turn-taking

**Note:** The Pipecat framework we build on is open-source (BSD-2-Clause) from Daily.co, further limiting any claims to the underlying architecture.

---

## Appendix: File References

| Innovation | Primary Files |
|------------|---------------|
| Context Restoration | `apps/interface/src/features/HtmlGeneration/lib/context-management.ts` |
| Voice Confusion | `apps/interface/src/features/RiveAvatarLipsync/lib/useLipsyncSpeechDetection.ts` |
| Conversation Beats | `apps/pipecat-daily-bot/bot/flows/pacing.py` |
| Applet Versioning | `apps/interface/src/features/HtmlGeneration/lib/versioning-system.ts` |
| Event Bus | `apps/pipecat-daily-bot/bot/eventbus/bus.py` |
| Warm Pool Dispatch | `apps/pipecat-daily-bot/bot/bot_operator.py` |
| Participant Name Resolution | `apps/pipecat-daily-bot/bot/flows/sanitization.py` |
| TTS Session Pool | `apps/chorus-tts/chorus_tts/kokoro_engine.py` |
| ~~Prism Refractory~~ | `packages/prism/src/refractory/index.ts` |
| ~~Incremental OAuth~~ | `packages/prism/src/core/oauth/incremental-auth.service.ts` |
| ~~Multi-User Facilitator~~ | `apps/pipecat-daily-bot/bot/flows/participantsAggregator.ts` |

---

## Appendix: Key Prior Art References

| Patent/Product | Owner | Relevance |
|----------------|-------|-----------|
| US12340181B1 | Fidelity | Conversation dialogue orchestration |
| US20170039750A1 | Intel | Avatar facial expression + speech animations |
| US12003673B2 | (Various) | Acoustic echo cancellation |
| **US20250080481A1** | HyperChat | **AI-facilitated multi-user conversations** (BLOCKS our multi-user facilitator) |
| Tavus Sparrow | Tavus.io | Turn-taking with confidence scoring |
| Hasura | Hasura Inc. | Automatic GraphQL schema generation |
| PostGraphile | Graphile | PostgreSQL ‚Üí GraphQL introspection |
| Otter.ai | Otter.ai Inc. | Multi-speaker transcription with diarization |
| Fireflies.ai | Fireflies | Meeting assistant with participant ID |

---

*This document updated December 29, 2025 with prior art research. Three innovations recommended for patent filing; three moved to "Not Worth Pursuing."*
